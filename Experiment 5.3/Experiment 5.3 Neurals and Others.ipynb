{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kukunuri.sai/.conda/envs/nilmtk_env/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n",
      "/home/kukunuri.sai/.conda/envs/nilmtk_env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/kukunuri.sai/.conda/envs/nilmtk_env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/kukunuri.sai/.conda/envs/nilmtk_env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/kukunuri.sai/.conda/envs/nilmtk_env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/kukunuri.sai/.conda/envs/nilmtk_env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/kukunuri.sai/.conda/envs/nilmtk_env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/kukunuri.sai/.conda/envs/nilmtk_env/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
      "  return f(*args, **kwds)\n",
      "/home/kukunuri.sai/.conda/envs/nilmtk_env/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from api import API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "redd = {\n",
    "  'power': {\n",
    "    'mains': ['apparent','active'],\n",
    "    'appliance': ['apparent','active']\n",
    "  },\n",
    "  'sample_rate': 60,\n",
    "  'appliances': ['fridge','air conditioner','electric furnace','washing machine'],\n",
    "  'methods': {\n",
    "     'Mean': {},\"FHMM_EXACT\":{},\"RNN\":{},\"Seq2Point\":{},\"Seq2Seq\":{},\"DAE\":{},\"WindowGRU\":{}\n",
    "      #\"AFHMM\":{},\"AFHMM_SAC\":{}\n",
    "      #\n",
    "  },\n",
    "  'train': {\n",
    "    'datasets': {\n",
    "      'Dataport': {\n",
    "        'path': '../dataport2.hdf5',\n",
    "        'buildings': {\n",
    "          54: {\n",
    "            'start_time': '2015-01-28',\n",
    "            'end_time': '2015-02-12'\n",
    "          },\n",
    "          56: {\n",
    "            'start_time': '2015-01-28',\n",
    "            'end_time': '2015-02-12'\n",
    "          },\n",
    "          57: {\n",
    "            'start_time': '2015-04-30',\n",
    "            'end_time': '2015-05-14'\n",
    "          },\n",
    "          62: {\n",
    "            'start_time': '2014-09-06',\n",
    "            'end_time': '2014-09-20'\n",
    "          },\n",
    "          63: {\n",
    "            'start_time': '2015-04-30',\n",
    "            'end_time': '2015-05-14'\n",
    "          },\n",
    "          64: {\n",
    "            'start_time': '2015-04-14',\n",
    "            'end_time': '2015-04-28'\n",
    "          },\n",
    "          65: {\n",
    "            'start_time': '2014-09-23',\n",
    "            'end_time': '2014-10-07'\n",
    "          },\n",
    "          69: {\n",
    "            'start_time': '2015-04-30',\n",
    "            'end_time': '2015-05-14'\n",
    "          },\n",
    "          71: {\n",
    "            'start_time': '2014-12-25',\n",
    "            'end_time': '2015-01-09'\n",
    "          },\n",
    "          72: {\n",
    "            'start_time': '2015-04-30',\n",
    "            'end_time': '2015-05-14'\n",
    "          }\n",
    "        }\n",
    "\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  'test': {\n",
    "    'datasets': {\n",
    "      'Datport': {\n",
    "        'path': '../dataport2.hdf5',\n",
    "        'buildings': {\n",
    "          94: {\n",
    "            'start_time': '2015-04-30',\n",
    "            'end_time': '2015-05-07'\n",
    "          },\n",
    "          103: {\n",
    "            'start_time': '2014-01-26',\n",
    "            'end_time': '2014-02-03'\n",
    "          },\n",
    "          113: {\n",
    "            'start_time': '2015-04-30',\n",
    "            'end_time': '2015-05-07'\n",
    "          },\n",
    "          117: {\n",
    "            'start_time': '2015-04-30',\n",
    "            'end_time': '2015-05-07'\n",
    "          },\n",
    "          122: {\n",
    "            'start_time': '2015-04-30',\n",
    "            'end_time': '2015-05-07'\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    },\n",
    "    'metrics': ['mae']\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started training for  WindowGRU\n",
      "<disaggregate.WindowGRU.WindowGRU object at 0x7febe7d22da0> False None\n",
      "Joint training for  WindowGRU\n",
      "............... Loading Data for training ...................\n",
      "Loading data for  Dataport  dataset\n",
      "Loading building ...  54\n",
      "Dropping missing values\n",
      "Train Jointly\n",
      "(21600, 1) (21600, 1) MultiIndex(levels=[['power'], ['active']],\n",
      "           codes=[[0], [0]],\n",
      "           names=['physical_quantity', 'type']) MultiIndex(levels=[['power'], ['active']],\n",
      "           codes=[[0], [0]],\n",
      "           names=['physical_quantity', 'type'])\n",
      "Loading building ...  56\n",
      "Dropping missing values\n",
      "Train Jointly\n",
      "(21600, 1) (21600, 1) MultiIndex(levels=[['power'], ['active']],\n",
      "           codes=[[0], [0]],\n",
      "           names=['physical_quantity', 'type']) MultiIndex(levels=[['power'], ['active']],\n",
      "           codes=[[0], [0]],\n",
      "           names=['physical_quantity', 'type'])\n",
      "Loading building ...  57\n",
      "Dropping missing values\n",
      "Train Jointly\n",
      "(20160, 1) (20160, 1) MultiIndex(levels=[['power'], ['active']],\n",
      "           codes=[[0], [0]],\n",
      "           names=['physical_quantity', 'type']) MultiIndex(levels=[['power'], ['active']],\n",
      "           codes=[[0], [0]],\n",
      "           names=['physical_quantity', 'type'])\n",
      "Loading building ...  62\n",
      "Dropping missing values\n",
      "Train Jointly\n",
      "(20160, 1) (20160, 1) MultiIndex(levels=[['power'], ['active']],\n",
      "           codes=[[0], [0]],\n",
      "           names=['physical_quantity', 'type']) MultiIndex(levels=[['power'], ['active']],\n",
      "           codes=[[0], [0]],\n",
      "           names=['physical_quantity', 'type'])\n",
      "Loading building ...  63\n",
      "Dropping missing values\n",
      "Train Jointly\n",
      "(20160, 1) (20160, 1) MultiIndex(levels=[['power'], ['active']],\n",
      "           codes=[[0], [0]],\n",
      "           names=['physical_quantity', 'type']) MultiIndex(levels=[['power'], ['active']],\n",
      "           codes=[[0], [0]],\n",
      "           names=['physical_quantity', 'type'])\n",
      "Loading building ...  64\n",
      "Dropping missing values\n",
      "Train Jointly\n",
      "(20160, 1) (20160, 1) MultiIndex(levels=[['power'], ['active']],\n",
      "           codes=[[0], [0]],\n",
      "           names=['physical_quantity', 'type']) MultiIndex(levels=[['power'], ['active']],\n",
      "           codes=[[0], [0]],\n",
      "           names=['physical_quantity', 'type'])\n",
      "Loading building ...  65\n",
      "Dropping missing values\n",
      "Train Jointly\n",
      "(20160, 1) (20160, 1) MultiIndex(levels=[['power'], ['active']],\n",
      "           codes=[[0], [0]],\n",
      "           names=['physical_quantity', 'type']) MultiIndex(levels=[['power'], ['active']],\n",
      "           codes=[[0], [0]],\n",
      "           names=['physical_quantity', 'type'])\n",
      "Loading building ...  69\n",
      "Dropping missing values\n",
      "Train Jointly\n",
      "(20160, 1) (20160, 1) MultiIndex(levels=[['power'], ['active']],\n",
      "           codes=[[0], [0]],\n",
      "           names=['physical_quantity', 'type']) MultiIndex(levels=[['power'], ['active']],\n",
      "           codes=[[0], [0]],\n",
      "           names=['physical_quantity', 'type'])\n",
      "Loading building ...  71\n",
      "Dropping missing values\n",
      "Train Jointly\n",
      "(21600, 1) (21600, 1) MultiIndex(levels=[['power'], ['active']],\n",
      "           codes=[[0], [0]],\n",
      "           names=['physical_quantity', 'type']) MultiIndex(levels=[['power'], ['active']],\n",
      "           codes=[[0], [0]],\n",
      "           names=['physical_quantity', 'type'])\n",
      "Loading building ...  72\n",
      "Dropping missing values\n",
      "Train Jointly\n",
      "(20160, 1) (20160, 1) MultiIndex(levels=[['power'], ['active']],\n",
      "           codes=[[0], [0]],\n",
      "           names=['physical_quantity', 'type']) MultiIndex(levels=[['power'], ['active']],\n",
      "           codes=[[0], [0]],\n",
      "           names=['physical_quantity', 'type'])\n",
      "Training processing\n",
      "First model training for  fridge\n",
      "Train on 175032 samples, validate on 30888 samples\n",
      "Epoch 1/10\n",
      "175032/175032 [==============================] - 659s 4ms/step - loss: 0.0018 - val_loss: 0.0016\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00157, saving model to windowgru-temp-weights-10.h5\n",
      "Epoch 2/10\n",
      "175032/175032 [==============================] - 605s 3ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.00157 to 0.00150, saving model to windowgru-temp-weights-10.h5\n",
      "Epoch 3/10\n",
      "175032/175032 [==============================] - 626s 4ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.00150 to 0.00142, saving model to windowgru-temp-weights-10.h5\n",
      "Epoch 4/10\n",
      "175032/175032 [==============================] - 623s 4ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00142 to 0.00126, saving model to windowgru-temp-weights-10.h5\n",
      "Epoch 5/10\n",
      "175032/175032 [==============================] - 622s 4ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.00126\n",
      "Epoch 6/10\n",
      "175032/175032 [==============================] - 627s 4ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00126 to 0.00122, saving model to windowgru-temp-weights-10.h5\n",
      "Epoch 7/10\n",
      "175032/175032 [==============================] - 627s 4ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00122 to 0.00120, saving model to windowgru-temp-weights-10.h5\n",
      "Epoch 8/10\n",
      "175032/175032 [==============================] - 634s 4ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00120 to 0.00113, saving model to windowgru-temp-weights-10.h5\n",
      "Epoch 9/10\n",
      "175032/175032 [==============================] - 626s 4ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.00113\n",
      "Epoch 10/10\n",
      "175032/175032 [==============================] - 631s 4ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.00113 to 0.00112, saving model to windowgru-temp-weights-10.h5\n",
      "First model training for  air conditioner\n",
      "Train on 175032 samples, validate on 30888 samples\n",
      "Epoch 1/10\n",
      "175032/175032 [==============================] - 639s 4ms/step - loss: 0.0488 - val_loss: 0.0312\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.03123, saving model to windowgru-temp-weights-4.h5\n",
      "Epoch 2/10\n",
      "175032/175032 [==============================] - 629s 4ms/step - loss: 0.0364 - val_loss: 0.0286\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.03123 to 0.02863, saving model to windowgru-temp-weights-4.h5\n",
      "Epoch 3/10\n",
      "175032/175032 [==============================] - 616s 4ms/step - loss: 0.0313 - val_loss: 0.0256\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.02863 to 0.02556, saving model to windowgru-temp-weights-4.h5\n",
      "Epoch 4/10\n",
      "175032/175032 [==============================] - 557s 3ms/step - loss: 0.0297 - val_loss: 0.0248\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.02556 to 0.02476, saving model to windowgru-temp-weights-4.h5\n",
      "Epoch 5/10\n",
      "175032/175032 [==============================] - 479s 3ms/step - loss: 0.0291 - val_loss: 0.0228\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.02476 to 0.02282, saving model to windowgru-temp-weights-4.h5\n",
      "Epoch 6/10\n",
      "175032/175032 [==============================] - 439s 3ms/step - loss: 0.0238 - val_loss: 0.0198\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.02282 to 0.01982, saving model to windowgru-temp-weights-4.h5\n",
      "Epoch 7/10\n",
      "175032/175032 [==============================] - 404s 2ms/step - loss: 0.0218 - val_loss: 0.0164\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.01982 to 0.01640, saving model to windowgru-temp-weights-4.h5\n",
      "Epoch 8/10\n",
      "175032/175032 [==============================] - 404s 2ms/step - loss: 0.0202 - val_loss: 0.0161\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.01640 to 0.01608, saving model to windowgru-temp-weights-4.h5\n",
      "Epoch 9/10\n",
      "175032/175032 [==============================] - 403s 2ms/step - loss: 0.0200 - val_loss: 0.0183\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.01608\n",
      "Epoch 10/10\n",
      "175032/175032 [==============================] - 405s 2ms/step - loss: 0.0183 - val_loss: 0.0131\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.01608 to 0.01305, saving model to windowgru-temp-weights-4.h5\n",
      "First model training for  electric furnace\n",
      "Train on 175032 samples, validate on 30888 samples\n",
      "Epoch 1/10\n",
      "175032/175032 [==============================] - 410s 2ms/step - loss: 0.0053 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00449, saving model to windowgru-temp-weights-4.h5\n",
      "Epoch 2/10\n",
      "175032/175032 [==============================] - 396s 2ms/step - loss: 0.0043 - val_loss: 0.0042\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.00449 to 0.00417, saving model to windowgru-temp-weights-4.h5\n",
      "Epoch 3/10\n",
      "175032/175032 [==============================] - 394s 2ms/step - loss: 0.0041 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.00417 to 0.00394, saving model to windowgru-temp-weights-4.h5\n",
      "Epoch 4/10\n",
      "175032/175032 [==============================] - 395s 2ms/step - loss: 0.0039 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00394 to 0.00375, saving model to windowgru-temp-weights-4.h5\n",
      "Epoch 5/10\n",
      "175032/175032 [==============================] - 395s 2ms/step - loss: 0.0037 - val_loss: 0.0034\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00375 to 0.00342, saving model to windowgru-temp-weights-4.h5\n",
      "Epoch 6/10\n",
      "175032/175032 [==============================] - 394s 2ms/step - loss: 0.0035 - val_loss: 0.0032\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00342 to 0.00322, saving model to windowgru-temp-weights-4.h5\n",
      "Epoch 7/10\n",
      "175032/175032 [==============================] - 395s 2ms/step - loss: 0.0033 - val_loss: 0.0031\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00322 to 0.00305, saving model to windowgru-temp-weights-4.h5\n",
      "Epoch 8/10\n",
      "175032/175032 [==============================] - 394s 2ms/step - loss: 0.0031 - val_loss: 0.0036\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.00305\n",
      "Epoch 9/10\n",
      "175032/175032 [==============================] - 394s 2ms/step - loss: 0.0030 - val_loss: 0.0027\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.00305 to 0.00275, saving model to windowgru-temp-weights-4.h5\n",
      "Epoch 10/10\n",
      "175032/175032 [==============================] - 394s 2ms/step - loss: 0.0035 - val_loss: 0.0048\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.00275\n",
      "First model training for  washing machine\n",
      "Train on 175032 samples, validate on 30888 samples\n",
      "Epoch 1/10\n",
      "175032/175032 [==============================] - 400s 2ms/step - loss: 2.9112e-04 - val_loss: 2.6084e-04\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00026, saving model to windowgru-temp-weights-1.h5\n",
      "Epoch 2/10\n",
      "175032/175032 [==============================] - 392s 2ms/step - loss: 2.4434e-04 - val_loss: 2.5905e-04\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.00026 to 0.00026, saving model to windowgru-temp-weights-1.h5\n",
      "Epoch 3/10\n",
      "175032/175032 [==============================] - 392s 2ms/step - loss: 2.4134e-04 - val_loss: 2.5592e-04\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.00026 to 0.00026, saving model to windowgru-temp-weights-1.h5\n",
      "Epoch 4/10\n",
      "175032/175032 [==============================] - 392s 2ms/step - loss: 2.4000e-04 - val_loss: 2.5394e-04\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00026 to 0.00025, saving model to windowgru-temp-weights-1.h5\n",
      "Epoch 5/10\n",
      "175032/175032 [==============================] - 393s 2ms/step - loss: 2.3821e-04 - val_loss: 2.5098e-04\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00025 to 0.00025, saving model to windowgru-temp-weights-1.h5\n",
      "Epoch 6/10\n",
      " 87552/175032 [==============>...............] - ETA: 3:06 - loss: 2.2992e-04"
     ]
    }
   ],
   "source": [
    "api_res = API(redd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_res.errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "vals = np.concatenate([np.expand_dims(df.values,axis=2) for df in api_res.errors],axis=2)\n",
    "\n",
    "\n",
    "cols = api_res.errors[0].columns\n",
    "indexes = api_res.errors[0].index\n",
    "\n",
    "\n",
    "mean = np.mean(vals,axis=2)\n",
    "std = np.std(vals,axis=2)\n",
    "print ('\\n\\n')\n",
    "print (\"Mean\")\n",
    "print (pd.DataFrame(mean,index=indexes,columns=cols))\n",
    "print ('\\n\\n')\n",
    "print (\"Variance\")\n",
    "print (pd.DataFrame(std,index=indexes,columns=cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
